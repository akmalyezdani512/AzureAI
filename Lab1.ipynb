{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable Resource Providers\n",
    "\n",
    "There are some resource providers that must be registered in your Azure subscription. Follow these steps to ensure that they're registered.\n",
    "\n",
    "Sign into the Azure portal at https://portal.azure.com using the Microsoft credentials associated with your subscription.\n",
    "On the Home page, select Subscriptions (or expand the â‰¡ menu, select All Services, and in the General category, select Subscriptions).\n",
    "Select your Azure subscription (if you have multiple subscriptions, select the one you created by redeeming your Azure Pass).\n",
    "In the blade for your subscription, in the pane on the left, in the Settings section, select Resource providers.\n",
    "In the list of resource providers, ensure the following providers are registered (if not, select them and click register):\n",
    "\n",
    "* Microsoft.Web\n",
    "* Microsoft.ManagedIdentity\n",
    "* Microsoft.Search\n",
    "* Microsoft.Storage\n",
    "* Microsoft.CognitiveServices\n",
    "* Microsoft.AlertsManagement\n",
    "* microsoft.insights\n",
    "* Microsoft.KeyVault\n",
    "* Microsoft.ContainerInstance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provision an Azure AI Services resource\n",
    "\n",
    "Azure AI Services are cloud-based services that encapsulate artificial intelligence capabilities you can incorporate into your applications. You can provision individual Azure AI services resources for specific APIs (for example, **Language** or **Vision**), or you can provision a single **Azure AI Services** resource that provides access to multiple Azure AI services APIs through a single endpoint and key. In this case, you'll use a single **Azure AI Services** resource.\n",
    "\n",
    "1. Open the Azure portal at `https://portal.azure.com`, and sign in using the Microsoft account associated with your Azure subscription.\n",
    "2. In the top search bar, search for *Azure AI services*, select **Azure AI Services**, and create an Azure AI services multi-service account resource with the following settings:\n",
    "    - **Subscription**: *Your Azure subscription*\n",
    "    - **Resource group**: *Choose or create a resource group (if you are using a restricted subscription, you may not have permission to create a new resource group - use the one provided)*\n",
    "    - **Region**: *Choose any available region*\n",
    "    - **Name**: *Enter a unique name*\n",
    "    - **Pricing tier**: Standard S0\n",
    "3. Select the required checkboxes and create the resource.\n",
    "4. Wait for deployment to complete, and then view the deployment details.\n",
    "5. Go to the resource and view its **Keys and Endpoint** page. This page contains the information that you will need to connect to your resource and use it from applications you develop. Specifically:\n",
    "    - An HTTP *endpoint* to which client applications can send requests.\n",
    "    - Two *keys* that can be used for authentication (client applications can use either key to authenticate).\n",
    "    - The *location* where the resource is hosted. This is required for requests to some (but not all) APIs.\n",
    "\n",
    "## Use a REST Interface\n",
    "\n",
    "The Azure AI services APIs are REST-based, so you can consume them by submitting JSON requests over HTTP. In this example, you'll explore a console application that uses the **Language** REST API to perform language detection; but the basic principle is the same for all of the APIs supported by the Azure AI Services resource.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COG_SERVICE_ENDPOINT=\"https://testaianshuooo7.cognitiveservices.azure.com/\"\n",
    "COG_SERVICE_KEY=\"a2c143d9d33e404488839fe03c5539c6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import http.client, base64, json, urllib\n",
    "from urllib import request, parse, error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"documents\": [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"text\": \"hii hello world\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "text = input (\"Enter some text\")\n",
    "jsonBody = {\n",
    "            \"documents\":[\n",
    "                {\"id\": 1,\n",
    "                 \"text\": text}\n",
    "            ]\n",
    "        }\n",
    "\n",
    "# Let's take a look at the JSON we'll send to the service\n",
    "print(json.dumps(jsonBody, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"documents\":[{\"id\":\"1\",\"detectedLanguage\":{\"name\":\"English\",\"iso6391Name\":\"en\",\"confidenceScore\":0.78},\"warnings\":[]}],\"errors\":[],\"modelVersion\":\"2024-04-01\"}\n"
     ]
    }
   ],
   "source": [
    "# Make an HTTP request to the REST interface\n",
    "uri = COG_SERVICE_ENDPOINT.rstrip('/').replace('https://', '')\n",
    "conn = http.client.HTTPSConnection(uri)\n",
    "\n",
    "# Add the authentication key to the request header\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Ocp-Apim-Subscription-Key': COG_SERVICE_KEY\n",
    "}\n",
    "\n",
    "# Use the Text Analytics language API\n",
    "conn.request(\"POST\", \"/text/analytics/v3.1/languages?\", str(jsonBody).encode('utf-8'), headers)\n",
    "\n",
    "# Send the request\n",
    "response = conn.getresponse()\n",
    "data = response.read().decode(\"UTF-8\")\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"documents\": [\n",
      "    {\n",
      "      \"id\": \"1\",\n",
      "      \"detectedLanguage\": {\n",
      "        \"name\": \"English\",\n",
      "        \"iso6391Name\": \"en\",\n",
      "        \"confidenceScore\": 0.78\n",
      "      },\n",
      "      \"warnings\": []\n",
      "    }\n",
      "  ],\n",
      "  \"errors\": [],\n",
      "  \"modelVersion\": \"2024-04-01\"\n",
      "}\n",
      "\n",
      "Language: English\n"
     ]
    }
   ],
   "source": [
    "# If the call was successful, get the response\n",
    "if response.status == 200:\n",
    "\n",
    "    # Display the JSON response in full (just so we can see it)\n",
    "    results = json.loads(data)\n",
    "    print(json.dumps(results, indent=2))\n",
    "\n",
    "    # Extract the detected language name for each document\n",
    "    for document in results[\"documents\"]:\n",
    "        print(\"\\nLanguage:\", document[\"detectedLanguage\"][\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use an SDK\n",
    "\n",
    "You can write code that consumes Azure AI services REST APIs directly, but there are software development kits (SDKs) for many popular programming languages, including Microsoft C#, Python, and Node.js. Using an SDK can greatly simplify development of applications that consume Azure AI services.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-ai-textanalytics==5.3.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create client using endpoint and key\n",
    "credential = AzureKeyCredential(COG_SERVICE_KEY)\n",
    "client = TextAnalyticsClient(endpoint=COG_SERVICE_ENDPOINT, credential=credential)\n",
    "\n",
    "# Call the service to get the detected language\n",
    "detectedLanguage = client.detect_language(documents = [text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English\n"
     ]
    }
   ],
   "source": [
    "print(detectedLanguage.primary_language.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import namespaces\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create client using endpoint and key\n",
    "credential = AzureKeyCredential(COG_SERVICE_KEY)\n",
    "cog_client = TextAnalyticsClient(endpoint=COG_SERVICE_ENDPOINT, credential=credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = input (\"Enter some text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DocumentError' object has no attribute 'primary_language'. The service was unable to process this document:\nDocument Id: 0\nError: InvalidDocument - Document text is empty.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get language\u001b[39;00m\n\u001b[0;32m      2\u001b[0m detectedLanguage \u001b[38;5;241m=\u001b[39m cog_client\u001b[38;5;241m.\u001b[39mdetect_language(documents\u001b[38;5;241m=\u001b[39m[text])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLanguage: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mdetectedLanguage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprimary_language\u001b[49m\u001b[38;5;241m.\u001b[39mname))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\azure\\ai\\textanalytics\\_models.py:891\u001b[0m, in \u001b[0;36mDocumentError.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    889\u001b[0m result_attrs \u001b[38;5;241m=\u001b[39m result_set\u001b[38;5;241m.\u001b[39mdifference(DocumentError()\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m result_attrs:\n\u001b[1;32m--> 891\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    892\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDocumentError\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. The service was unable to process this document:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument Id: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    894\u001b[0m             attr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mcode, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mmessage\n\u001b[0;32m    895\u001b[0m         )\n\u001b[0;32m    896\u001b[0m     )\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDocumentError\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    899\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DocumentError' object has no attribute 'primary_language'. The service was unable to process this document:\nDocument Id: 0\nError: InvalidDocument - Document text is empty.\n"
     ]
    }
   ],
   "source": [
    "# Get language\n",
    "detectedLanguage = cog_client.detect_language(documents=[text])[0]\n",
    "print('\\nLanguage: {}'.format(detectedLanguage.primary_language.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate sentiment\n",
    "\n",
    "Sentiment analysis is a commonly used technique to classify text as positive or negative (or possible neutral or mixed). It's commonly used to analyze social media posts, product reviews, and other items where the sentiment of the text may provide useful insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = input (\"Enter some text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DocumentError' object has no attribute 'sentiment'. The service was unable to process this document:\nDocument Id: 0\nError: InvalidDocument - Document text is empty.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get sentiment\u001b[39;00m\n\u001b[0;32m      2\u001b[0m sentimentAnalysis \u001b[38;5;241m=\u001b[39m cog_client\u001b[38;5;241m.\u001b[39manalyze_sentiment(documents\u001b[38;5;241m=\u001b[39m[text])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSentiment: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43msentimentAnalysis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentiment\u001b[49m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\azure\\ai\\textanalytics\\_models.py:891\u001b[0m, in \u001b[0;36mDocumentError.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    889\u001b[0m result_attrs \u001b[38;5;241m=\u001b[39m result_set\u001b[38;5;241m.\u001b[39mdifference(DocumentError()\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m result_attrs:\n\u001b[1;32m--> 891\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    892\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDocumentError\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. The service was unable to process this document:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument Id: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    894\u001b[0m             attr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mcode, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mmessage\n\u001b[0;32m    895\u001b[0m         )\n\u001b[0;32m    896\u001b[0m     )\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDocumentError\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    899\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DocumentError' object has no attribute 'sentiment'. The service was unable to process this document:\nDocument Id: 0\nError: InvalidDocument - Document text is empty.\n"
     ]
    }
   ],
   "source": [
    "# Get sentiment\n",
    "sentimentAnalysis = cog_client.analyze_sentiment(documents=[text])[0]\n",
    "print(\"\\nSentiment: {}\".format(sentimentAnalysis.sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify key phrases\n",
    "It can be useful to identify key phrases in a body of text to help determine the main topics that it discusses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = input (\"Enter some text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Key Phrases:\n",
      "\tworld\n"
     ]
    }
   ],
   "source": [
    "# Get key phrases\n",
    "phrases = cog_client.extract_key_phrases(documents=[text])[0].key_phrases\n",
    "if len(phrases) > 0:\n",
    "    print(\"\\nKey Phrases:\")\n",
    "    for phrase in phrases:\n",
    "        print('\\t{}'.format(phrase))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract entities\n",
    "\n",
    "Often, documents or other bodies of text mention people, places, time periods, or other entities. The text Analytics API can detect multiple categories (and subcategories) of entity in your text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = input (\"Enter some text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entities\n",
      "\tworld (Person)\n"
     ]
    }
   ],
   "source": [
    "# Get entities\n",
    "entities = cog_client.recognize_entities(documents=[text])[0].entities\n",
    "if len(entities) > 0:\n",
    "    print(\"\\nEntities\")\n",
    "    for entity in entities:\n",
    "        print('\\t{} ({})'.format(entity.text, entity.category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract linked entities\n",
    "In addition to categorized entities, the Text Analytics API can detect entities for which there are known links to data sources, such as Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get linked entities\n",
    "entities = cog_client.recognize_linked_entities(documents=[text])[0].entities\n",
    "if len(entities) > 0:\n",
    "    print(\"\\nLinks\")\n",
    "    for linked_entity in entities:\n",
    "        print('\\t{} ({})'.format(linked_entity.name, linked_entity.url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate Text\n",
    "Azure AI Translator is a service that enables you to translate text between languages.\n",
    "\n",
    "For example, suppose a travel agency wants to examine hotel reviews that have been submitted to the company's web site, standardizing on English as the language that is used for analysis. By using Azure AI Translator, they can determine the language each review is written in, and if it is not already English, translate it from whatever source language it was written in into English."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect language\n",
    "Azure AI Translator can automatically detect the source language of text to be translated, but it also enables you to explicitly detect the language in which text is written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'isTranslationSupported': True, 'isTransliterationSupported': False, 'language': 'en', 'score': 0.98}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "# Use the Azure AI Translator detect function\n",
    "\n",
    "translator_endpoint = 'https://api.cognitive.microsofttranslator.com'\n",
    "\n",
    "path = '/detect'\n",
    "url = translator_endpoint + path\n",
    "\n",
    "# Build the request\n",
    "params = {\n",
    "    'api-version': '3.0'\n",
    "}\n",
    "\n",
    "headers = {\n",
    "'Ocp-Apim-Subscription-Key': COG_SERVICE_KEY,\n",
    "'Ocp-Apim-Subscription-Region': \"eastus\",\n",
    "'Content-type': 'application/json'\n",
    "}\n",
    "\n",
    "body = [{\n",
    "    'text': text\n",
    "}]\n",
    "\n",
    "# Send the request and get response\n",
    "request = requests.post(url, params=params, headers=headers, json=body)\n",
    "response = request.json()\n",
    "\n",
    "# Parse JSON array and get language\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate text\n",
    "Now that your application can determine the language in which reviews are written, you can use Azure AI Translator to translate any non-English reviews into English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Azure AI Translator translate function\n",
    "path = '/translate'\n",
    "url = translator_endpoint + path\n",
    "\n",
    "# Build the request\n",
    "params = {\n",
    "    'api-version': '3.0',\n",
    "    'from': 'en',\n",
    "    'to': ['fr']\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': COG_SERVICE_KEY,\n",
    "    'Ocp-Apim-Subscription-Region': \"eastus\",\n",
    "    'Content-type': 'application/json'\n",
    "}\n",
    "\n",
    "body = [{\n",
    "    'text': text\n",
    "}]\n",
    "\n",
    "# Send the request and get response\n",
    "request = requests.post(url, params=params, headers=headers, json=body)\n",
    "response = request.json()\n",
    "\n",
    "# Parse JSON array and get translation\n",
    "translation = response[0][\"translations\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salut bonjour le monde\n"
     ]
    }
   ],
   "source": [
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
